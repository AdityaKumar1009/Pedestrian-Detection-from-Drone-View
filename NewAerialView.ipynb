{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaKumar1009/Pedestrian-Detection-from-Drone-View/blob/main/NewAerialView.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqqE1exsQAGu",
        "outputId": "b44e0e80-ffbd-481b-88af-f417bcfdf801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7sFLzz7QiXX",
        "outputId": "5c942613-a68d-4159-e685-03dca84d8a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ultralytics\n"
          ]
        }
      ],
      "source": [
        "#!git clone https://github.com/ultralytics/ultralytics.git\n",
        "%cd /content/drive/MyDrive/ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0OOsHjqSIRJ",
        "outputId": "25a1458b-bc91-46d3-9097-f09c93547b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-24.0\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBmqSYFwSOgX",
        "outputId": "9aa687c4-64fe-4bc5-8966-8999d39a2608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 524, in entrypoint\n",
            "    raise ValueError(f\"Invalid 'mode={mode}'. Valid modes are {MODES}.\\n{CLI_HELP_MSG}\")\n",
            "ValueError: Invalid 'mode=<module 'ultralytics.utils.checks' from '/usr/local/lib/python3.10/dist-packages/ultralytics/utils/checks.py'>'. Valid modes are {'train', 'benchmark', 'export', 'predict', 'track', 'val'}.\n",
            "\n",
            "    Arguments received: ['yolo', 'mode=checks']. Ultralytics 'yolo' commands use the following syntax:\n",
            "\n",
            "        yolo TASK MODE ARGS\n",
            "\n",
            "        Where   TASK (optional) is one of {'classify', 'obb', 'pose', 'detect', 'segment'}\n",
            "                MODE (required) is one of {'train', 'benchmark', 'export', 'predict', 'track', 'val'}\n",
            "                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n",
            "                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n",
            "\n",
            "    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n",
            "        yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n",
            "\n",
            "    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n",
            "        yolo predict model=yolov8n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n",
            "\n",
            "    3. Val a pretrained detection model at batch-size 1 and image size 640:\n",
            "        yolo val model=yolov8n.pt data=coco8.yaml batch=1 imgsz=640\n",
            "\n",
            "    4. Export a YOLOv8n classification model to ONNX format at image size 224 by 128 (no TASK required)\n",
            "        yolo export model=yolov8n-cls.pt format=onnx imgsz=224,128\n",
            "\n",
            "    6. Explore your datasets using semantic search and SQL with a simple GUI powered by Ultralytics Explorer API\n",
            "        yolo explorer\n",
            "\n",
            "    5. Run special commands:\n",
            "        yolo help\n",
            "        yolo checks\n",
            "        yolo version\n",
            "        yolo settings\n",
            "        yolo copy-cfg\n",
            "        yolo cfg\n",
            "\n",
            "    Docs: https://docs.ultralytics.com\n",
            "    Community: https://community.ultralytics.com\n",
            "    GitHub: https://github.com/ultralytics/ultralytics\n",
            "    \n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "!yolo mode=checks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "21gXCgxw92dF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NMe158Yu95yj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHfxntz1T3If"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl53U_VqUWEc"
      },
      "outputs": [],
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWT8TLquSfuK"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lgRZtQtKSl49",
        "outputId": "022e3d27-e833-4b91-c857-96defad18ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.28-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting certifi==2023.7.22 (from roboflow)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting python-magic (from roboflow)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Downloading roboflow-1.1.28-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.9.0.80\n",
            "    Uninstalling opencv-python-headless-4.9.0.80:\n",
            "      Successfully uninstalled opencv-python-headless-4.9.0.80\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.2.2\n",
            "    Uninstalling certifi-2024.2.2:\n",
            "      Successfully uninstalled certifi-2024.2.2\n",
            "Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.28\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cv2",
                  "cycler",
                  "idna"
                ]
              },
              "id": "480f6e0f6f564ba0b13d2cfbb09726b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics==8.0.196 is required but found version=8.2.2, to fix: `pip install ultralytics==8.0.196`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/datasets/Aerial-Person-Detection-3 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1615470/1615470 [01:01<00:00, 26352.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to /content/datasets/Aerial-Person-Detection-3 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13989/13989 [00:07<00:00, 1832.24it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Bpp1VwceWTHOjeEq3LwS\")\n",
        "project = rf.workspace(\"aerial-person-detection\").project(\"aerial-person-detection\")\n",
        "version = project.version(3)\n",
        "dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcDTADNGU-3W",
        "outputId": "bc1bc4d4-baaa-4592-8c55-8f121b4da372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/last.pt, data=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/last.pt, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 47.7MB/s]\n",
            "2024-05-03 18:08:26.703899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-03 18:08:26.703962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-03 18:08:26.841272: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752482  ultralytics.nn.modules.head.Detect           [6, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3012018 parameters, 3012002 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/labels.cache... 6445 images, 0 backgrounds, 0 corrupt: 100% 6445/6445 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/images/0000137_02220_d_0000163_jpg.rf.c76c4efa8d7cb12599ecbc67c1fb7afb.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/images/0000140_00118_d_0000002_jpg.rf.6ac6b72a99c9fff9561b50b9dafbe0a3.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/images/9999945_00000_d_0000114_jpg.rf.58b19b78116cb3d88b3b8a65de976d4b.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/images/9999987_00000_d_0000049_jpg.rf.b2ddd3f8fac21d1a5131495d6f2cd563.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/labels.cache... 545 images, 0 backgrounds, 0 corrupt: 100% 545/545 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Resuming training /content/drive/MyDrive/ultralytics/runs/detect/train/weights/last.pt from epoch 70 to 100 total epochs\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 416 train, 416 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     70/100      3.18G      1.485     0.9806     0.8867        940        416: 100% 403/403 [08:54<00:00,  1.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [05:33<00:00, 18.52s/it]\n",
            "                   all        545      36988      0.402      0.274      0.276      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     71/100      2.74G      1.479     0.9812     0.8863        635        416: 100% 403/403 [05:27<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.29it/s]\n",
            "                   all        545      36988       0.41      0.271      0.276       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     72/100      2.74G      1.478     0.9796     0.8886        797        416: 100% 403/403 [05:30<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.30it/s]\n",
            "                   all        545      36988      0.412      0.272      0.278      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     73/100      3.06G      1.482     0.9796     0.8881       1146        416: 100% 403/403 [05:27<00:00,  1.23it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:15<00:00,  1.19it/s]\n",
            "                   all        545      36988      0.413       0.27      0.278      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     74/100      2.85G      1.498     0.9898     0.8875        947        416: 100% 403/403 [05:29<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.30it/s]\n",
            "                   all        545      36988      0.404      0.275      0.279      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     75/100      2.36G      1.485       0.98     0.8865       1322        416: 100% 403/403 [05:31<00:00,  1.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.29it/s]\n",
            "                   all        545      36988      0.398      0.274      0.278      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     76/100      2.75G      1.479     0.9774     0.8862        879        416: 100% 403/403 [05:37<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.22it/s]\n",
            "                   all        545      36988      0.402      0.275      0.281      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     77/100      2.94G       1.48     0.9806     0.8871        668        416: 100% 403/403 [05:43<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.25it/s]\n",
            "                   all        545      36988        0.4      0.277      0.281      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     78/100      2.71G      1.474      0.971     0.8867        586        416: 100% 403/403 [05:42<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.26it/s]\n",
            "                   all        545      36988      0.395      0.278      0.279      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     79/100      2.32G      1.472     0.9671     0.8861       1110        416: 100% 403/403 [05:44<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.27it/s]\n",
            "                   all        545      36988      0.407      0.271       0.28      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     80/100      3.44G      1.477     0.9696     0.8866        927        416: 100% 403/403 [05:46<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.29it/s]\n",
            "                   all        545      36988      0.398      0.276       0.28      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     81/100      2.57G      1.472     0.9672     0.8844       1062        416: 100% 403/403 [05:35<00:00,  1.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.26it/s]\n",
            "                   all        545      36988      0.403      0.278       0.28      0.151\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     82/100      3.19G      1.463     0.9581      0.883        841        416: 100% 403/403 [05:38<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.28it/s]\n",
            "                   all        545      36988      0.398      0.275       0.28      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     83/100      3.94G      1.471     0.9624     0.8847       1081        416: 100% 403/403 [05:37<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.28it/s]\n",
            "                   all        545      36988      0.404       0.28      0.281      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     84/100      2.67G      1.467     0.9603     0.8835       1031        416: 100% 403/403 [05:38<00:00,  1.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.23it/s]\n",
            "                   all        545      36988      0.395       0.28      0.281      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     85/100      2.69G      1.459     0.9551     0.8825        639        416: 100% 403/403 [05:43<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.27it/s]\n",
            "                   all        545      36988      0.389      0.283      0.281      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     86/100      2.78G      1.465     0.9556     0.8828        969        416: 100% 403/403 [05:47<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.22it/s]\n",
            "                   all        545      36988      0.388      0.282      0.282      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     87/100      4.68G      1.463     0.9568     0.8833        704        416: 100% 403/403 [05:47<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.26it/s]\n",
            "                   all        545      36988      0.385      0.284      0.284      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     88/100      2.71G      1.452     0.9498     0.8815       1153        416: 100% 403/403 [05:46<00:00,  1.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.24it/s]\n",
            "                   all        545      36988      0.399      0.279      0.282      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     89/100      3.12G       1.45     0.9451     0.8809        716        416: 100% 403/403 [05:44<00:00,  1.17it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.23it/s]\n",
            "                   all        545      36988      0.397      0.281      0.283      0.154\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     90/100      2.52G       1.44     0.9383     0.8789       1177        416: 100% 403/403 [05:42<00:00,  1.18it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.30it/s]\n",
            "                   all        545      36988      0.399      0.276      0.281      0.154\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     91/100      3.06G      1.437     0.9345     0.8824        419        416: 100% 403/403 [05:19<00:00,  1.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.28it/s]\n",
            "                   all        545      36988      0.398      0.281      0.283      0.155\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     92/100      2.15G       1.42     0.9158     0.8813        556        416: 100% 403/403 [05:07<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.27it/s]\n",
            "                   all        545      36988      0.392       0.28      0.282      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     93/100      2.92G      1.415     0.9104     0.8791        593        416: 100% 403/403 [05:11<00:00,  1.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.23it/s]\n",
            "                   all        545      36988      0.387      0.283      0.282      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     94/100      3.56G      1.416     0.9088      0.879        680        416: 100% 403/403 [05:11<00:00,  1.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.26it/s]\n",
            "                   all        545      36988      0.394      0.281      0.284      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     95/100      2.68G      1.402     0.9006     0.8774        522        416: 100% 403/403 [05:10<00:00,  1.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.23it/s]\n",
            "                   all        545      36988      0.392      0.284      0.284      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     96/100      2.64G      1.403      0.899     0.8774        448        416: 100% 403/403 [05:06<00:00,  1.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:13<00:00,  1.31it/s]\n",
            "                   all        545      36988      0.399       0.28      0.284      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     97/100      3.18G      1.406     0.9002     0.8787        719        416: 100% 403/403 [04:58<00:00,  1.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:15<00:00,  1.16it/s]\n",
            "                   all        545      36988      0.399      0.284      0.285      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     98/100      2.28G      1.395     0.8925     0.8773        498        416: 100% 403/403 [04:59<00:00,  1.34it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.27it/s]\n",
            "                   all        545      36988      0.415      0.277      0.284      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "     99/100      2.87G      1.397     0.8911     0.8766        525        416: 100% 403/403 [05:23<00:00,  1.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:14<00:00,  1.23it/s]\n",
            "                   all        545      36988      0.401      0.281      0.284      0.157\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "    100/100      3.12G      1.397     0.8923     0.8755        656        416: 100% 403/403 [05:13<00:00,  1.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:15<00:00,  1.13it/s]\n",
            "                   all        545      36988      0.408      0.279      0.285      0.158\n",
            "\n",
            "31 epochs completed in 3.115 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 18/18 [00:35<00:00,  1.99s/it]\n",
            "                   all        545      36988      0.409      0.279      0.285      0.158\n",
            "               bicycle        545       1283      0.155     0.0156     0.0266    0.00896\n",
            "                   bus        545        251      0.469      0.335      0.343      0.223\n",
            "                   car        545      13986      0.575      0.636      0.632      0.395\n",
            "            motorcycle        545       4861      0.403      0.189      0.194     0.0684\n",
            "                person        545      13890      0.443      0.233      0.244     0.0823\n",
            "                 truck        545       2717      0.409      0.267      0.271      0.168\n",
            "Speed: 0.3ms preprocess, 4.6ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo task=detect mode=train resume model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/last.pt batch=16 epochs=100 data=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/data.yaml imgsz=416"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/best.pt source=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/images/0000002_00448_d_0000015_jpg.rf.1b6a07e09eaecc1bd971e080495ceeba.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXF5EX69Vgb0",
        "outputId": "8695a01e-9dbc-458f-cc28-c029c0efacd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/train/images/0000002_00448_d_0000015_jpg.rf.1b6a07e09eaecc1bd971e080495ceeba.jpg: 256x416 10 cars, 74 motorcycles, 3 persons, 2 trucks, 176.9ms\n",
            "Speed: 1.8ms preprocess, 176.9ms inference, 3228.6ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/best.pt source=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000001_03499_d_0000006_jpg.rf.cc6c2ccfc71c76d8d6b2e40b223fa4c1.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OvkreqKWsKx",
        "outputId": "03e784c4-8445-45ff-c25a-383ccad91a0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000001_03499_d_0000006_jpg.rf.cc6c2ccfc71c76d8d6b2e40b223fa4c1.jpg: 256x416 14 cars, 1 person, 2 trucks, 79.6ms\n",
            "Speed: 2.9ms preprocess, 79.6ms inference, 1974.8ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/best.pt source=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000055_00000_d_0000109_jpg.rf.819455a7a5da65ed25d31b677b7fe269.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir2neSuTW5Vx",
        "outputId": "70bf2781-bda0-4c5c-ce4b-2eef9033fe91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000055_00000_d_0000109_jpg.rf.819455a7a5da65ed25d31b677b7fe269.jpg: 256x416 1 motorcycle, 40 persons, 217.2ms\n",
            "Speed: 4.6ms preprocess, 217.2ms inference, 2759.1ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/best.pt source=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000103_00180_d_0000026_jpg.rf.28778abaf22be0424197db71f6b6eb59.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGEdG2WdXRBL",
        "outputId": "224f931a-9e7d-4d5e-c35c-99120945fc2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000103_00180_d_0000026_jpg.rf.28778abaf22be0424197db71f6b6eb59.jpg: 256x416 1 motorcycle, 2 persons, 88.3ms\n",
            "Speed: 2.6ms preprocess, 88.3ms inference, 1944.1ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task=detect mode=predict model=/content/drive/MyDrive/ultralytics/runs/detect/train/weights/best.pt source=/content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000153_00001_d_0000001_jpg.rf.1295361cfdc22c94ea23b4ffba198756.jpg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va9tH2pEXbDc",
        "outputId": "d5a2107d-71ac-49df-e525-ffd2bb832eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.7 ğŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006818 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/ultralytics/Aerial-Person-Detection-3/valid/images/0000153_00001_d_0000001_jpg.rf.1295361cfdc22c94ea23b4ffba198756.jpg: 256x416 14 cars, 5 motorcycles, 9 persons, 98.7ms\n",
            "Speed: 2.0ms preprocess, 98.7ms inference, 2028.1ms postprocess per image at shape (1, 3, 256, 416)\n",
            "Results saved to \u001b[1mruns/detect/predict5\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyP9Zid66AcvcbX5EJDC8Fw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}